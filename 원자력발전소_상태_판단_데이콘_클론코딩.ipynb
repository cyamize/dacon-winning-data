{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "원자력발전소 상태 판단 데이콘 클론코딩",
      "provenance": [],
      "authorship_tag": "ABX9TyNZQgCs8+4DWFYMaFGf0Pw6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyamize/dacon-winning-data/blob/main/%EC%9B%90%EC%9E%90%EB%A0%A5%EB%B0%9C%EC%A0%84%EC%86%8C_%EC%83%81%ED%83%9C_%ED%8C%90%EB%8B%A8_%EB%8D%B0%EC%9D%B4%EC%BD%98_%ED%81%B4%EB%A1%A0%EC%BD%94%EB%94%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUGmk-GDXHg0"
      },
      "source": [
        "훈련했을 때 학습 데이터에 과도하게 초점이 맞춰 머신이 훈련 될 수 있어 과적합 우려가 있다.\n",
        "\n",
        "과적합을 막기위해 교차검증을 사용하는데, 이 때 학습세트와 검증 세트를 나눠 반복해서 검증한다. 이걸 k값 만큼의 폴드세트에 k번의 학습과 검증을 k번 평가하는것이 k-fold 교차검증이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfoJl4cmX2i9"
      },
      "source": [
        "또한 lightgbm은 트리 기반의 학습 알고리즘으로 데이터가 클 때 속도가 빠르고 gpu로 처리가 가능한 방법이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S0rEEb3ZlaM"
      },
      "source": [
        "# Library & Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp83bBSmJByK"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import lightgbm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdrU9n5lVvVi"
      },
      "source": [
        "import multiprocessing # 여러 개의 cpu에게 작업을 분산시키는 역할\n",
        "from multiprocessing import Pool\n",
        "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
        "from data_loader_v2 import data_loader_v2 # 자체적으로 만든 data loader version_v2\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib # 텍스트 상태의 데이터가 아닌 파이썬 객체 자체를 파일로 저장\n",
        "train_folder = 'data/train/'\n",
        "test_folder = 'data/test/'\n",
        "train_label_path = '/data/train_label.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKLut-PqZr0D"
      },
      "source": [
        "# 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t88UDrg_3Lxg"
      },
      "source": [
        "train_list = os.listdir(train_folder)\n",
        "test_list = os.listdir(test_folder)\n",
        "train_label = pd.read_csv(train_label_path, index_col=0)\n",
        "\n",
        "# 모든 csv 파일의 상태_B로 변화는 시점이 같다고 가정\n",
        "# 그러나, 개별 CSV파일의 상태_B로 변화는 시점은 상이할 수 있다\n",
        "def data_loader_all_v2(func, files, folder ='', train_label=None, event_time=10,nrows=60):\n",
        "  func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)\n",
        "  if __name__ == '__main__':\n",
        "    pool = Pool(processes = multiprocessing.cpu_count())\n",
        "    df_list = list(pool.imap(func_fixed,files))\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "  combined_df = pd.concat(df_list)\n",
        "\n",
        "  return combined_df                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQQmXJUf0NX"
      },
      "source": [
        "train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, train_label=train_label, event_time=10, nrows=60)\n",
        "test = data_loader_all_v2(data_loader_v2,test_list, folder=test_folder, train_label=None, event_time=20, nrows=60)\n",
        "\n",
        "y = train['label']\n",
        "train.drop('label', axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ-wnkphmjg-"
      },
      "source": [
        "# 모델 학습, 검증, 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YoAqkRtmi1O"
      },
      "source": [
        "parms = {\n",
        "    'learning_rate' : 0.06,\n",
        "    'num_leaves' : 400,\n",
        "    'n_estimators' : 300,\n",
        "    'max_depth': -1,\n",
        "    'min_child_weight' : 3, \n",
        "    'subsample' : 0.8,\n",
        "    'colsample_bytree' : 0.5,\n",
        "    'objective' : 'multiclass',\n",
        "    'n_jobs': -1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XYn-Y6tmodn"
      },
      "source": [
        "# 4FOLD, 3SEED ENSEMBLE\n",
        "# 총 12개의 모델을 평균내어 예측한다\n",
        "\n",
        "lucky_seed=[4885,1992,1022]\n",
        "\n",
        "for num,rs in enumerate(lucky_seed):\n",
        "\n",
        "  kfold = KFold(n_splits=4, random_state = rs,shuffle = True)\n",
        "\n",
        "  # dacon code\n",
        "  cv=np.zeros((train.shape[0],198))\n",
        "\n",
        "  for n, (train_idx, validation_idx) in enumerate(kfold.split(train)):\n",
        "\n",
        "    x_train, x_validation = train.iloc[train_idx], train.iloc[validation_idx]\n",
        "    y_train, y_validation = y.iloc[train_idx], y.loc[validation_idx]\n",
        "\n",
        "    model = lightgbm.LGBMClassifier(**parms, random_state=rs)\n",
        "\n",
        "    model.fit(x_train, y_train, eval_set = [(x_validation, y_validation)], early_stopping_rounds=30,\n",
        "              verbose = 100)\n",
        "    joblib.dump(model, '../2_Code_pred/%s_fold_model_%s.pkl'%(n,rs))\n",
        "\n",
        "    # CROSS-VALIDATION , EVALUATE CV\n",
        "    cv[validation_idx,:] = model.predict_proba(x_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruadFP4-XkJz"
      },
      "source": [
        "# MODEL LOAD & TEST PREDICT\n",
        "# 12 MODELS 평균 사용\n",
        "models = os.listdir('../2_Code_pred/')\n",
        "models_list = [x for x in models if x.endswith(\".pkl\")]\n",
        "assert len(models_list) ==12\n",
        "temp_predictions = np.zeros((test.shape[0],198))\n",
        "\n",
        "for m in models_list:\n",
        "    model = joblib.load('../2_Code_pred/'+m)\n",
        "    predict_proba = model.predict_proba(test)\n",
        "    temp_predictions += predict_proba/12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV_PX3QjXl5y"
      },
      "source": [
        "# dacon code\n",
        "submission = pd.DataFrame(data=np.zeros((test.shape[0],198)))\n",
        "submission.index = test.index \n",
        "submission.index.name = 'id'\n",
        "submission+=temp_predictions\n",
        "\n",
        "submission = submission.sort_index()\n",
        "submission = submission.groupby('id').mean()\n",
        "submission.to_csv('submission.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsuV3GqhmBx5"
      },
      "source": [
        "# 결과\n",
        "\n",
        "### 데이터 전처리\n",
        "PCA, Feature 정규화, Min-Max Scaling은 성능 향상에 도움이 되지 않음 Object와 NAN 값을 0으로 바꾸어 주는 전처리만 진행\n",
        "\n",
        "### 모델 학습 검증\n",
        "\n",
        "- Lgbm 모델 선택\n",
        "\n",
        "Random Forest, Xgboost, LightGBM 모델 비교 결과 LGBM의 성능이 가장 좋았다.\n",
        "\n",
        "- K-fold & Random seed를 사용한 모델 하이퍼 파라미터 튜닝\n",
        "\n",
        "Robust 한 모델을 만들기 위해 4Kfold * 3seed 총 12개의 모델을 만듬 Early stopping 값을 작게 설정하여 over-fitting 방지 min_child_weight 값을 CV를 통해 최적화 하여 over-fitting 방지 Soft-voting 예측 방법 선택\n",
        "\n",
        "- Soft-voting 예측\n",
        "\n",
        "예측 시 Hard-voting 방식과 Probability를 평균내는 Soft-voting 방식을 실험 evaluation metric이 log-loss였기 때문에 probability를 평균내는 방식의 성능이 좋았음 12개의 모델의 예측을 평균 하는 방식으로 최종 결과물 제출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyJKuD9fmLH2"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}